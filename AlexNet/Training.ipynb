{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AlexNet-Prototyp: Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AlexNet (Model.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Input\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3), name=\"alexnet_input\")\n",
    "\n",
    "# Schicht 1: Convolution\n",
    "l1 = tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4, padding=\"same\")(inputs)\n",
    "l1 = tf.keras.layers.BatchNormalization()(l1)\n",
    "l1 = tf.keras.layers.ReLU()(l1)\n",
    "l1 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2)(l1)\n",
    "\n",
    "# Schicht 2: Convolution\n",
    "l2 = tf.keras.layers.Conv2D(filters=256, kernel_size=5, strides=1, padding=\"same\")(l1)\n",
    "l2 = tf.keras.layers.BatchNormalization()(l2)\n",
    "l2 = tf.keras.layers.ReLU()(l2)\n",
    "l2 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2)(l2)\n",
    "\n",
    "# Schicht 3: Convolution\n",
    "l3 = tf.keras.layers.Conv2D(filters=384, kernel_size=3, strides=1, padding=\"same\")(l2)\n",
    "l3 = tf.keras.layers.ReLU()(l3)\n",
    "\n",
    "# Schicht 4: Convolution\n",
    "l4 = tf.keras.layers.Conv2D(filters=384, kernel_size=3, strides=1, padding=\"same\")(l3)\n",
    "l4 = tf.keras.layers.ReLU()(l4)\n",
    "\n",
    "# Schicht 5: Convolution\n",
    "l5 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding=\"same\")(l4)\n",
    "l5 = tf.keras.layers.ReLU()(l5)\n",
    "l5 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2)(l5)\n",
    "\n",
    "# Schicht 6: Dense\n",
    "l6_pre = tf.keras.layers.Flatten()(l5)\n",
    "\n",
    "l6 = tf.keras.layers.Dense(units=4096)(l6_pre)\n",
    "l6 = tf.keras.layers.ReLU()(l6)\n",
    "l6 = tf.keras.layers.Dropout(rate=0.5)(l6)\n",
    "\n",
    "# Schicht 7: Dense\n",
    "l7 = tf.keras.layers.Dense(units=4096)(l6)\n",
    "l7 = tf.keras.layers.ReLU()(l7)\n",
    "l7 = tf.keras.layers.Dropout(rate=0.5)(l7)\n",
    "\n",
    "# Schicht 8: Dense\n",
    "l8 = tf.keras.layers.Dense(units=1000)(l7)\n",
    "l8 = tf.keras.layers.Softmax(dtype=tf.float32, name=\"alexnet_output\")(l8)\n",
    "\n",
    "alexnet = tf.keras.models.Model(inputs=inputs, outputs=l8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Callbacks\n",
    "- **Early Stopping**: Das Training wird beendet, wenn sich eine der überwachten Metriken nicht mehr verbessert, hier *Validation Accuracy*. Sie berechnet, wie oft Vorhersagen mit One-Hot Labels übereinstimmen.\n",
    "- **Reduce Learning Rate**: Gemäß der Autorspezifikation wird die Lernrate von AlexNet um den faktor 10 reduziert, wenn sich die Genauigkeit der *Loss Validation Accuracy* nicht verbessert. Die *Loss Validation Accuracy* ist die Summe der Fehler, die für jedes Beispiel in Trainings- oder Validierungssätzen gemacht wurden. *Loss* gibt an, wie gut sich ein Modell nach jeder Iteration der Optimierung verhält. *Accuracy* wird verwendet, um die Leistung des Algorithmus zu messen.\n",
    "- **Tensorboard**: damit werden die Trainings- und Validierungsmetriken auf Tensorboard für die Trainingsanalyse veröffentlicht"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_categorical_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_categorical_accuracy\",\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=10e-8,\n",
    ")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"log\",\n",
    "    histogram_freq=2,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq=\"epoch\",\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=2,\n",
    "    embeddings_metadata=None,\n",
    ")\n",
    "callbacks = [early_stop, reduce_learning_rate, tensorboard]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metriken: Training und Validierung\n",
    "### Legende:\n",
    "- **TP** - True Positive\n",
    "- **FP** - False Positive\n",
    "- **TN** - True Negative\n",
    "- **FN** - False Negative\n",
    "\n",
    "### Metriken:\n",
    "- **Categorical Accuracy** = $\\frac{TP+FP}{TP+FP+TN+FN}$\n",
    "- **Precision** = $\\frac{TP}{TP+FP}$\n",
    "- **Recall** = $\\frac{TP}{TP+FN}$\n",
    "- **F1 Score** = $2*\\frac{Precision*Recall}{Precision+Recall}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.FalseNegatives(),\n",
    "    tf.keras.metrics.FalsePositives(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tfa.metrics.F1Score(num_classes=10)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "- **Epochs**: Anzahl der Zyklen des Trainings. Gemäß des Papers wurde AlexNet in 90 Epochen trainiert\n",
    "- **SGD** (Stochastic Gradient Descent): Gemäß des Papers wurde AlexNet mit SGD trainiert\n",
    "- Validierungs- und Trainingdaten werden noch ermittelt (tbd - to be determined)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 90\n",
    "\n",
    "# Compilieren und Trainieren\n",
    "alexnet.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.01, momentum=0.9, nesterov=False, name='SGD'\n",
    "    ),\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "history = alexnet.fit(\n",
    "    epochs=EPOCHS,\n",
    "          # validation and training data tbd\n",
    "          validation_freq=1,\n",
    "          callbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}